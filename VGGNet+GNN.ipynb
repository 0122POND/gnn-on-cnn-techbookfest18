{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyOkwQi5/wnbb8Nr3HaPb4RF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# å¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n","!pip install torch-geometric -q"],"metadata":{"id":"kA2ajKOCdEF3","executionInfo":{"status":"ok","timestamp":1747477040074,"user_tz":-540,"elapsed":2453,"user":{"displayName":"é»’æ²¼ç¾æ¨¹","userId":"00169067044641761241"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms, models\n","from torch.utils.data import DataLoader\n","from torch_geometric.nn import GCNConv\n","from sklearn.metrics import top_k_accuracy_score\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from tqdm import tqdm"],"metadata":{"id":"DB7zO1hKdI_g","executionInfo":{"status":"ok","timestamp":1747477040076,"user_tz":-540,"elapsed":3,"user":{"displayName":"é»’æ²¼ç¾æ¨¹","userId":"00169067044641761241"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"wrA1mDZ4dKv2","executionInfo":{"status":"ok","timestamp":1747477040078,"user_tz":-540,"elapsed":1,"user":{"displayName":"é»’æ²¼ç¾æ¨¹","userId":"00169067044641761241"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™\n","transform = transforms.Compose([\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","])\n","\n","train_dataset = datasets.CIFAR10(root=\"./data\", train=True, transform=transform, download=True)\n","val_dataset = datasets.CIFAR10(root=\"./data\", train=False, transform=transform, download=True)\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n","val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2)\n","\n","class VGG(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        # VGG16ã®ä»£æ›¿æ§‹é€ ï¼ˆ32x32å…¥åŠ›å¯¾å¿œï¼‰\n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=3, padding=1),  # (B, 64, 32, 32)\n","            nn.ReLU(True),\n","            nn.Conv2d(64, 64, kernel_size=3, padding=1),  # (B, 64, 32, 32)\n","            nn.ReLU(True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),        # (B, 64, 16, 16)\n","\n","            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n","            nn.ReLU(True),\n","            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n","            nn.ReLU(True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),        # (B, 128, 8, 8)\n","\n","            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n","            nn.ReLU(True),\n","            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n","            nn.ReLU(True),\n","            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n","            nn.ReLU(True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),        # (B, 256, 4, 4)\n","        )\n","\n","        self.classifier = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(256 * 4 * 4, 512),\n","            nn.ReLU(True),\n","            nn.Dropout(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(True),\n","            nn.Dropout(),\n","            nn.Linear(512, 10)\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        return self.classifier(x)\n","\n","\n","class VGG_GNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        # CIFAR-10å‘ã‘VGGã‚¹ã‚¿ã‚¤ãƒ«ã®ç‰¹å¾´æŠ½å‡ºéƒ¨\n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n","            nn.ReLU(True),\n","            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n","            nn.ReLU(True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),        # 16x16\n","\n","            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n","            nn.ReLU(True),\n","            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n","            nn.ReLU(True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),        # 8x8\n","\n","            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n","            nn.ReLU(True),\n","            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n","            nn.ReLU(True),\n","            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n","            nn.ReLU(True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),        # 4x4\n","        )\n","\n","        self.gnn = GCNConv(256, 256)\n","        self.classifier = nn.Linear(256, 10)\n","\n","    def forward(self, x):\n","        x = self.features(x)  # (B, 256, 4, 4)\n","        B, C, H, W = x.shape\n","        x = x.view(B, C, -1).permute(0, 2, 1)  # (B, 16, 256)\n","\n","        edge_index = self._create_edges(H, W).to(x.device)\n","        out = []\n","        for i in range(B):\n","            gnn_out = self.gnn(x[i], edge_index)  # (16, 256)\n","            pooled = gnn_out.mean(dim=0)          # (256,)\n","            out.append(pooled)\n","        out = torch.stack(out)  # (B, 256)\n","        return self.classifier(out)\n","\n","    def _create_edges(self, H, W):\n","        # æ ¼å­æ§‹é€ ã®éš£æ¥ãƒãƒ¼ãƒ‰ã‚’å®šç¾©\n","        edges = []\n","        for i in range(H):\n","            for j in range(W):\n","                idx = i * W + j\n","                if i < H - 1:\n","                    edges.append([idx, (i + 1) * W + j])\n","                if j < W - 1:\n","                    edges.append([idx, i * W + (j + 1)])\n","        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n","        return edge_index\n","\n","\n","# EarlyStoppingã®ã‚¯ãƒ©ã‚¹å®šç¾©\n","class EarlyStopping:\n","    def __init__(self, patience=10):\n","        self.patience = patience\n","        self.best_score = None\n","        self.counter = 0\n","        self.early_stop = False\n","\n","    def __call__(self, score):\n","        if self.best_score is None or score > self.best_score:\n","            self.best_score = score\n","            self.counter = 0\n","        else:\n","            self.counter += 1\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","\n","# è©•ä¾¡é–¢æ•°\n","def evaluate(model, loader):\n","    model.eval()\n","    top1_correct = 0\n","    preds_all, labels_all = [], []\n","    loop = tqdm(loader, desc=\"Evaluating\")\n","    with torch.no_grad():\n","        for images, labels in loop:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            preds = outputs.argmax(dim=1)\n","            top1_correct += (preds == labels).sum().item()\n","            preds_all.append(outputs.cpu())\n","            labels_all.append(labels.cpu())\n","    preds_all = torch.cat(preds_all).numpy()\n","    labels_all = torch.cat(labels_all).numpy()\n","    top1 = 100 * top1_correct / len(loader.dataset)\n","    top5 = 100 * top_k_accuracy_score(labels_all, preds_all, k=5)\n","    return top1, top5\n","\n","def train(model, loader, optimizer, criterion, val_loader, max_epochs=50, model_name=\"model\"):\n","    model.to(device)\n","    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=2, factor=0.5, verbose=True)\n","    early_stopper = EarlyStopping(patience=3)\n","\n","    train_losses, train_accuracies, val_accuracies = [], [], []\n","\n","    best_model_state = None\n","    best_val_acc = -1\n","    best_epoch = -1\n","\n","    for epoch in range(max_epochs):\n","        model.train()\n","        total, correct, total_loss = 0, 0, 0\n","        loop = tqdm(loader, desc=f\"Epoch {epoch+1}\")\n","        for images, labels in loop:\n","            images, labels = images.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            preds = outputs.argmax(dim=1)\n","            total += labels.size(0)\n","            correct += (preds == labels).sum().item()\n","            total_loss += loss.item()\n","            acc = 100 * correct / total\n","            loop.set_postfix(loss=loss.item(), acc=f\"{acc:.2f}%\")\n","\n","        train_losses.append(total_loss / len(loader))\n","        train_accuracies.append(100 * correct / total)\n","\n","        val_top1, _ = evaluate(model, val_loader)\n","        val_accuracies.append(val_top1)\n","        scheduler.step(val_top1)\n","\n","        # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜\n","        if val_top1 > best_val_acc:\n","            best_val_acc = val_top1\n","            best_model_state = model.state_dict()\n","            best_epoch = epoch + 1  # 1-based\n","\n","        early_stopper(val_top1)\n","        if early_stopper.early_stop:\n","            print(f\"â¹ï¸ Early stopping at epoch {epoch+1}\")\n","            break\n","\n","    # ä¿å­˜å‡¦ç†\n","    os.makedirs(\"checkpoints\", exist_ok=True)\n","    model_path = f\"checkpoints/{model_name}_best.pt\"\n","    torch.save(best_model_state, model_path)\n","    print(f\"ğŸ’¾ ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ï¼ˆepoch {best_epoch}ï¼‰ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {model_path}\")\n","\n","    # æœ€å¾Œã«ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ç›´ã—ã¦è¿”ã™\n","    model.load_state_dict(best_model_state)\n","    return model, train_losses, train_accuracies, val_accuracies, best_epoch\n","\n","def plot_training_curves(train_losses, train_accuracies, val_accuracies, output_path=\"plots/training_summary.png\"):\n","    import matplotlib.pyplot as plt\n","    import os\n","\n","    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n","\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(train_losses, label=\"Train Loss\")\n","    plt.plot(train_accuracies, label=\"Train Accuracy\")\n","    plt.plot(val_accuracies, label=\"Validation Accuracy\")\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Value\")\n","    plt.title(\"Training Summary\")\n","    plt.legend()\n","    plt.grid(True)\n","    plt.savefig(output_path)\n","    print(f\"ğŸ“ˆ å­¦ç¿’æ›²ç·šã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_path}\")\n","    plt.close()"],"metadata":{"id":"tgnyVCbDdOcw","executionInfo":{"status":"ok","timestamp":1747477041768,"user_tz":-540,"elapsed":1689,"user":{"displayName":"é»’æ²¼ç¾æ¨¹","userId":"00169067044641761241"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OiG6CuTJc3dZ","executionInfo":{"status":"ok","timestamp":1747478002730,"user_tz":-540,"elapsed":960958,"user":{"displayName":"é»’æ²¼ç¾æ¨¹","userId":"00169067044641761241"}},"outputId":"0689b973-378d-4364-e8ec-d93ac9a9ce11"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["â–¶ï¸ Training Plain VGG16...\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [00:07<00:00, 107.42it/s, acc=31.79%, loss=1.29]\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:01<00:00, 138.92it/s]\n","Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [00:06<00:00, 117.30it/s, acc=50.61%, loss=1.06]\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:01<00:00, 133.13it/s]\n","Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [00:06<00:00, 118.72it/s, acc=59.59%, loss=1.27]\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:01<00:00, 137.06it/s]\n","Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [00:06<00:00, 118.82it/s, acc=65.32%, loss=1.14]\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:01<00:00, 132.98it/s]\n","Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [00:06<00:00, 120.53it/s, acc=69.29%, loss=1.28]\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:01<00:00, 135.11it/s]\n","Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [00:06<00:00, 118.53it/s, acc=71.99%, loss=1.25]\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:01<00:00, 133.89it/s]\n","Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [00:06<00:00, 117.80it/s, acc=73.81%, loss=0.726]\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:01<00:00, 133.34it/s]\n","Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [00:06<00:00, 121.51it/s, acc=75.50%, loss=0.889]\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:01<00:00, 139.97it/s]\n","Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [00:06<00:00, 121.90it/s, acc=77.04%, loss=0.543]\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:01<00:00, 139.91it/s]\n","Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [00:06<00:00, 122.10it/s, acc=78.25%, loss=0.481]\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:01<00:00, 141.93it/s]\n","Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [00:06<00:00, 120.00it/s, acc=78.98%, loss=0.528]\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:01<00:00, 140.62it/s]\n","Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [00:06<00:00, 120.84it/s, acc=80.08%, loss=0.834]\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:01<00:00, 127.16it/s]\n","Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [00:06<00:00, 120.74it/s, acc=80.42%, loss=0.253]\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:01<00:00, 142.90it/s]\n","Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [00:06<00:00, 122.78it/s, acc=81.39%, loss=0.46]\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:01<00:00, 132.37it/s]\n","Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [00:06<00:00, 120.73it/s, acc=81.66%, loss=0.397]\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:01<00:00, 135.71it/s]\n","Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [00:06<00:00, 121.52it/s, acc=82.34%, loss=0.361]\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:01<00:00, 142.45it/s]\n","Epoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [00:06<00:00, 122.11it/s, acc=83.22%, loss=0.321]\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:01<00:00, 142.62it/s]\n","Epoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [00:06<00:00, 120.76it/s, acc=83.43%, loss=0.576]\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:01<00:00, 137.05it/s]\n","Epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [00:06<00:00, 121.34it/s, acc=83.83%, loss=0.384]\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:01<00:00, 131.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["â¹ï¸ Early stopping at epoch 19\n","ğŸ’¾ ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ï¼ˆepoch 16ï¼‰ã‚’ä¿å­˜ã—ã¾ã—ãŸ: checkpoints/vgg_plain_best.pt\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:01<00:00, 142.52it/s]\n","/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","ğŸ“Š VGG16 - Top-1 Accuracy: 77.55%, Top-5 Accuracy: 98.08% (Best Epoch: 16)\n","ğŸ“ˆ å­¦ç¿’æ›²ç·šã‚’ä¿å­˜ã—ã¾ã—ãŸ: plots/vgg_plain_summary.png\n","\n","â–¶ï¸ Training VGG16 + GNN...\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [00:59<00:00, 13.21it/s, acc=31.42%, loss=1.4]\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:07<00:00, 20.74it/s]\n","Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [00:59<00:00, 13.10it/s, acc=51.33%, loss=1.14]\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:07<00:00, 20.41it/s]\n","Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [00:59<00:00, 13.12it/s, acc=62.76%, loss=1.08]\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:07<00:00, 20.33it/s]\n","Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [00:59<00:00, 13.21it/s, acc=69.25%, loss=1.51]\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:07<00:00, 20.74it/s]\n","Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [00:59<00:00, 13.17it/s, acc=74.22%, loss=0.893]\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:07<00:00, 20.04it/s]\n","Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [00:59<00:00, 13.20it/s, acc=77.14%, loss=0.833]\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:07<00:00, 20.56it/s]\n","Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [00:59<00:00, 13.22it/s, acc=79.79%, loss=0.874]\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:08<00:00, 19.60it/s]\n","Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [00:59<00:00, 13.20it/s, acc=81.41%, loss=0.84]\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:07<00:00, 19.70it/s]\n","Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [00:59<00:00, 13.25it/s, acc=82.92%, loss=0.801]\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:07<00:00, 20.70it/s]\n","Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [00:59<00:00, 13.23it/s, acc=84.31%, loss=0.445]\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:08<00:00, 19.22it/s]\n","Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [00:59<00:00, 13.21it/s, acc=85.67%, loss=0.271]\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:07<00:00, 20.48it/s]\n","Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [01:00<00:00, 12.95it/s, acc=86.59%, loss=0.671]\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:07<00:00, 20.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["â¹ï¸ Early stopping at epoch 12\n","ğŸ’¾ ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ï¼ˆepoch 9ï¼‰ã‚’ä¿å­˜ã—ã¾ã—ãŸ: checkpoints/vgg_gnn_best.pt\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:07<00:00, 20.76it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","ğŸ“Š VGG16 + GNN - Top-1 Accuracy: 80.16%, Top-5 Accuracy: 99.08% (Best Epoch: 9)\n","ğŸ“ˆ å­¦ç¿’æ›²ç·šã‚’ä¿å­˜ã—ã¾ã—ãŸ: plots/vgg_gnn_summary.png\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["# Plain VGG16 ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨ä¿å­˜\n","print(\"â–¶ï¸ Training Plain VGG16...\")\n","vgg_plain = PlainVGG()\n","optimizer_plain = torch.optim.Adam(vgg_plain.parameters(), lr=0.001)\n","vgg_plain, plain_losses, plain_accs, plain_val_accs, plain_best_epoch = train(\n","    vgg_plain, train_loader, optimizer_plain, nn.CrossEntropyLoss(), val_loader, model_name=\"vgg_plain\")\n","\n","plain_top1, plain_top5 = evaluate(vgg_plain, val_loader)\n","print(f\"\\nğŸ“Š VGG16 - Top-1 Accuracy: {plain_top1:.2f}%, Top-5 Accuracy: {plain_top5:.2f}% (Best Epoch: {plain_best_epoch})\")\n","plot_training_curves(plain_losses, plain_accs, plain_val_accs, output_path=\"plots/vgg_plain_summary.png\")\n","\n","\n","# VGG + GNN ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨ä¿å­˜\n","print(\"\\nâ–¶ï¸ Training VGG16 + GNN...\")\n","vgg_gnn = VGG_GNN()\n","optimizer_gnn = torch.optim.Adam(vgg_gnn.parameters(), lr=0.001)\n","vgg_gnn, gnn_losses, gnn_accs, gnn_val_accs, gnn_best_epoch = train(\n","    vgg_gnn, train_loader, optimizer_gnn, nn.CrossEntropyLoss(), val_loader, model_name=\"vgg_gnn\")\n","\n","gnn_top1, gnn_top5 = evaluate(vgg_gnn, val_loader)\n","print(f\"\\nğŸ“Š VGG16 + GNN - Top-1 Accuracy: {gnn_top1:.2f}%, Top-5 Accuracy: {gnn_top5:.2f}% (Best Epoch: {gnn_best_epoch})\")\n","plot_training_curves(gnn_losses, gnn_accs, gnn_val_accs, output_path=\"plots/vgg_gnn_summary.png\")"]}]}